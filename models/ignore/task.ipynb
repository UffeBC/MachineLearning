{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Model Development\n",
    "\n",
    "## Problem Defintion\n",
    "\n",
    "We are facing a challenge in locating golf balls in an image taken over a golf course, which is meant to mimic a real golf course. The program should be able to provide the locations of the balls based on the input of a new image. We have a dataset consisting of 100 different images, each containing up to 14 golf balls. These images have been processed and bounding boxes have been added to indicate where the golf balls are located in the images. So our datasets contains raw images: \"images\" and labelled images with bounding boxes: \"json_labeling\".\n",
    "\n",
    "We aim to develop a model that can receive an image of golf balls and return the coordinates of their locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may use any third-party library of your choice.\n",
    "Understanding of the code is essential.\n",
    "If the model you use is not covered in this course, then we wonâ€™t evaluate you for \n",
    "a compre-hensive grasp of the theories behind it.  We would however ask you questions in \n",
    "a rather highlevel regarding the model you use.\n",
    "You can build one or more models for your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction & Data Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully organized into train, validation, and test sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil # For copying files\n",
    "import json \n",
    "from sklearn.model_selection import train_test_split # For splitting data\n",
    "\n",
    "# Define the paths to your images and JSON annotations\n",
    "images_path = '../images'\n",
    "annotations_path = '../json_labeling'\n",
    "\n",
    "# Load all image and annotation file names\n",
    "images = [f for f in os.listdir(images_path) if f.endswith('.png')]\n",
    "annotations = [f for f in os.listdir(annotations_path) if f.endswith('.json')]\n",
    "\n",
    "# Ensure the images and annotations lists are sorted to maintain alignment\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size=0.30, random_state=42)\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(test_images, test_annotations, test_size=0.50, random_state=42)\n",
    "\n",
    "# Helper function to copy files\n",
    "def copy_files(files, source_dir, target_dir):\n",
    "    for file in files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(target_dir, file))\n",
    "\n",
    "# Create directories for the dataset splits if they don't already exist\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for kind in ['images', 'annotations']:\n",
    "        os.makedirs(f'data/{split}/{kind}', exist_ok=True)\n",
    "\n",
    "# Copy the files to the respective directories\n",
    "copy_files(train_images, images_path, 'data/train/images')\n",
    "copy_files(train_annotations, annotations_path, 'data/train/annotations')\n",
    "copy_files(val_images, images_path, 'data/validation/images')\n",
    "copy_files(val_annotations, annotations_path, 'data/validation/annotations')\n",
    "copy_files(test_images, images_path, 'data/test/images')\n",
    "copy_files(test_annotations, annotations_path, 'data/test/annotations')\n",
    "\n",
    "print(\"Data successfully organized into train, validation, and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Annotation file data/train/annotations\\label_1.json not found. Skipping example.\n",
      "Error: Annotation file data/train/annotations\\label_2.json not found. Skipping example.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'annotations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m#train_annotations = [os.path.join('data/train/annotations', name.replace('.json', '.png')) for name in train_images]\u001b[39;00m\n\u001b[0;32m     81\u001b[0m train_annotations \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train/annotations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_images))]\n\u001b[1;32m---> 83\u001b[0m create_tf_records(train_images, train_annotations, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.tfrecord\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 73\u001b[0m, in \u001b[0;36mcreate_tf_records\u001b[1;34m(images, annotations, output_path)\u001b[0m\n\u001b[0;32m     71\u001b[0m writer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mTFRecordWriter(output_path)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, annotation_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(images, annotations):\n\u001b[1;32m---> 73\u001b[0m     tf_example \u001b[38;5;241m=\u001b[39m create_tf_example(image_path, annotation_path)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf_example:\n\u001b[0;32m     75\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite(tf_example\u001b[38;5;241m.\u001b[39mSerializeToString())\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36mcreate_tf_example\u001b[1;34m(image_path, annotation_path)\u001b[0m\n\u001b[0;32m     39\u001b[0m classes_text \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List of string class name of bounding box (1 per box)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m classes \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List of integer class id of bounding box (1 per box, assuming 'golf ball' is 1)\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     43\u001b[0m     xmins\u001b[38;5;241m.\u001b[39mappend(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxmin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(width))\n\u001b[0;32m     44\u001b[0m     xmaxs\u001b[38;5;241m.\u001b[39mappend(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxmax\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(width))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'annotations'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from PIL import Image\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_tf_example(image_path, annotation_path):\n",
    "    # Load the image and get its dimensions\n",
    "    try:\n",
    "        with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
    "            encoded_jpg = fid.read()\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not read image {image_path}. Skipping example.\")\n",
    "        return None\n",
    "    \n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    try:\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "    except IOError:\n",
    "        print(f\"Error: Failed to open image {image_path}. Skipping example.\")\n",
    "        return None\n",
    "    width, height = image.size\n",
    "\n",
    "    # Load annotations\n",
    "    try:\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            annotation = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Annotation file {annotation_path} not found. Skipping example.\")\n",
    "        return None\n",
    "\n",
    "    # Prepare the example\n",
    "    xmins = []  # List of normalized left x coordinates in bounding box (1 per box)\n",
    "    xmaxs = []  # List of normalized right x coordinates in bounding box (1 per box)\n",
    "    ymins = []  # List of normalized top y coordinates in bounding box (1 per box)\n",
    "    ymaxs = []  # List of normalized bottom y coordinates in bounding box (1 per box)\n",
    "    classes_text = []  # List of string class name of bounding box (1 per box)\n",
    "    classes = []  # List of integer class id of bounding box (1 per box, assuming 'golf ball' is 1)\n",
    "\n",
    "    for obj in annotation['annotations']:\n",
    "        xmins.append(obj['xmin'] / float(width))\n",
    "        xmaxs.append(obj['xmax'] / float(width))\n",
    "        ymins.append(obj['ymin'] / float(height))\n",
    "        ymaxs.append(obj['ymax'] / float(height))\n",
    "        classes_text.append(obj['label'].encode('utf8'))\n",
    "        classes.append(1)  # Assumes the class ID for 'golf ball' is 1\n",
    "\n",
    "    if not xmins:  # Checks if there are any bounding boxes\n",
    "        print(f\"No bounding boxes found in {annotation_path}. Skipping example.\")\n",
    "        return None\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[os.path.basename(image_path).encode('utf8')])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[os.path.basename(image_path).encode('utf8')])),\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_jpg])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'jpeg' if image_path.lower().endswith('.jpeg') else b'png'])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "def create_tf_records(images, annotations, output_path):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    for image_path, annotation_path in zip(images, annotations):\n",
    "        tf_example = create_tf_example(image_path, annotation_path)\n",
    "        if tf_example:\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "# Example of how to call create_tf_records for the training dataset\n",
    "train_images = [os.path.join('data/train/images', name) for name in os.listdir('data/train/images')]\n",
    "#train_annotations = [os.path.join('data/train/annotations', name.replace('.json', '.png')) for name in train_images]\n",
    "train_annotations = [f\"data/train/annotations/label_{i+1}.json\" for i in range(len(train_images))]\n",
    "\n",
    "create_tf_records(train_images, train_annotations, 'train.tfrecord')\n",
    "\n",
    "# Repeat for validation and test datasets...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Explanation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
