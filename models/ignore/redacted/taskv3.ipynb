{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2888109941780567\n",
      "Epoch [2/5], Loss: 0.24019828528165818\n",
      "Epoch [3/5], Loss: 0.23112022310495375\n",
      "Epoch [4/5], Loss: 0.2127714893221855\n",
      "Epoch [5/5], Loss: 0.19394513189792634\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "class ObjectDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_classes, num_boxes=20):\n",
    "        super(ObjectDetectionCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_boxes = num_boxes\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Output size after convolutions\n",
    "        self.final_conv_size = 16 * 61 * 61  # Update according to your network architecture and input size\n",
    "        \n",
    "        # Detection layer: class scores and bounding boxes\n",
    "        self.detector = nn.Linear(self.final_conv_size, num_boxes * (4 + num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the features:\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Detector layer\n",
    "        x = self.detector(x)\n",
    "        # Reshape to [batch_size, num_boxes, 4 (bbox) + num_classes]\n",
    "        x = x.view(-1, self.num_boxes, 4 + self.num_classes)\n",
    "        return x\n",
    "\n",
    "def load_image(image_path, resize=True):\n",
    "    with Image.open(image_path) as img:\n",
    "        if resize:\n",
    "            img = img.resize((256, 256))\n",
    "        img = np.array(img, dtype=np.float32) / 255.0  # Normalize and ensure type is float32\n",
    "        img = img.transpose((2, 0, 1))  # Rearrange to channel first\n",
    "        return torch.from_numpy(img).float()  # Ensure the tensor is float\n",
    "\n",
    "\n",
    "def load_labels(json_path, img_width=256, img_height=256, num_boxes=20):\n",
    "    \"\"\"Load labels for detection from JSON file.\"\"\"\n",
    "    labels = np.zeros((num_boxes, 5))  # Assuming one class, change 5 to 4 + num_classes if multiple classes\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for i, box in enumerate(data['boxes']):\n",
    "            if i >= num_boxes:\n",
    "                break\n",
    "            x_center, y_center = float(box['x']), float(box['y'])\n",
    "            width, height = float(box['width']), float(box['height'])\n",
    "            # Normalize to [0, 1]\n",
    "            x_min = (x_center - width / 2) / img_width\n",
    "            y_min = (y_center - height / 2) / img_height\n",
    "            x_max = (x_center + width / 2) / img_width\n",
    "            y_max = (y_center + height / 2) / img_height\n",
    "            # Labels for object detection: [class, x_min, y_min, x_max, y_max]\n",
    "            labels[i] = [1, x_min, y_min, x_max, y_max]  # Assuming 'ball' class is 1\n",
    "    return labels\n",
    "\n",
    "# Example usage:\n",
    "# model = ObjectDetectionCNN(num_classes=1)  # Adjust num_classes based on your dataset\n",
    "# image = load_image('../images/image_1.png')\n",
    "# labels = load_labels('../json_labeling/label_1.json')\n",
    "# output = model(image.unsqueeze(0))  # Add batch dimension\n",
    "\n",
    "\n",
    "# Define a simple dataset class\n",
    "class DetectionDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir):\n",
    "        self.image_paths = [os.path.join(image_dir, x) for x in sorted(os.listdir(image_dir))]\n",
    "        self.label_paths = [os.path.join(label_dir, x) for x in sorted(os.listdir(label_dir))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = load_image(self.image_paths[idx])\n",
    "        labels = load_labels(self.label_paths[idx])  # Assuming load_labels is also defined correctly\n",
    "        return image, labels\n",
    "\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = DetectionDataset('../images', '../json_labeling')\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = ObjectDetectionCNN(num_classes=1)\n",
    "model.train()\n",
    "\n",
    "# Define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.float(), labels.float()  # Ensure both are float32\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Loss calculation\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader)}')\n",
    "\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_predictions(image, predictions, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Visualizes predictions by drawing bounding boxes on the image.\n",
    "    `predictions` should be a tensor of shape [num_boxes, 5 (class_score, x_min, y_min, x_max, y_max)].\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1)\n",
    "    # Display the image\n",
    "    ax.imshow(image.permute(1, 2, 0))  # Convert from CHW to HWC for matplotlib\n",
    "\n",
    "    for pred in predictions:\n",
    "        score, x_min, y_min, x_max, y_max = pred\n",
    "        if score > threshold:  # Only display predictions above a certain threshold\n",
    "            rect = patches.Rectangle((x_min * 256, y_min * 256), (x_max - x_min) * 256, (y_max - y_min) * 256, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "# Assuming you have a single image tensor and corresponding output from the model\n",
    "image, _ = dataset[0]  # Get the first image and its label (ignored here)\n",
    "image = image.unsqueeze(0)  # Add batch dimension\n",
    "output = model(image)  # Get model output\n",
    "visualize_predictions(image.squeeze(0), output.squeeze(0))  # Remove batch dimension for visualization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
