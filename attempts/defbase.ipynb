{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Image and Annotations Function:\n",
    "#Loads an image and its corresponding annotations from the JSON file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Preprocessing Function:\n",
    "#Resize and normalize images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanso\\AppData\\Local\\Temp\\ipykernel_1248\\2541950852.py:25: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((img_width, img_height), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_data(img_folder, json_folder, img_width=224, img_height=224):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # List all files in the img_folder assuming the naming convention matches your description\n",
    "    for img_file in sorted(os.listdir(img_folder)):\n",
    "        # Extract the number from the image file name, assuming the format \"image_1.png\"\n",
    "        img_number = img_file.split('_')[1].split('.')[0]\n",
    "        \n",
    "        # Construct the full file paths\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        label_path = os.path.join(json_folder, f\"label_{img_number}.json\")\n",
    "\n",
    "        #print(f\"Loading image: {img_path}\")\n",
    "        #print(f\"Loading label: {label_path}\")\n",
    "\n",
    "        # Load and resize image using PIL\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.resize((img_width, img_height), Image.ANTIALIAS)\n",
    "                img = np.array(img, dtype=np.float32) / 255.0  # Normalize image data to 0-1\n",
    "                images.append(img)\n",
    "        except IOError:\n",
    "            print(f\"Failed to load or process image at {img_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load labels\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Label file not found at {label_path}\")\n",
    "            continue\n",
    "        \n",
    "        with open(label_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            box_data = []\n",
    "            for item in data['boxes']:\n",
    "                if item['label'] == 'ball':\n",
    "                    # Normalize coordinates\n",
    "                    x = float(item['x']) / data['width']\n",
    "                    y = float(item['y']) / data['height']\n",
    "                    width = float(item['width']) / data['width']\n",
    "                    height = float(item['height']) / data['height']\n",
    "                    box_data.append([x * img_width, y * img_height, width * img_width, height * img_height])\n",
    "            labels.append(box_data)\n",
    "\n",
    "    return np.array(images), labels\n",
    "\n",
    "# Usage\n",
    "img_folder = '../images'\n",
    "json_folder = '../json_labeling'\n",
    "images, labels = load_and_preprocess_data(img_folder, json_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "def display_image_with_boxes_pil(image, boxes, expand_by=4):\n",
    "    \"\"\"\n",
    "    Displays an image with bounding boxes drawn on it using PIL, with each box slightly larger.\n",
    "    Also converts the image to grayscale.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The image array (numpy array).\n",
    "    - boxes: A list of bounding boxes, each represented as [center_x, center_y, width, height].\n",
    "    - expand_by: Number of pixels to increase the size of each box by (total, not per side).\n",
    "    \"\"\"\n",
    "    # Ensure the image is in uint8 format\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (255 * image).astype(np.uint8)\n",
    "\n",
    "    # Convert numpy array image to PIL Image\n",
    "    pil_img = Image.fromarray(image)\n",
    "    pil_img = pil_img.convert('L')  # Convert to grayscale\n",
    "\n",
    "    # Create a drawing context\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    # Draw each box\n",
    "    for box in boxes:\n",
    "        center_x, center_y, width, height = map(int, box)\n",
    "        top_left = (center_x - (width // 2) - (expand_by // 2), center_y - (height // 2) - (expand_by // 2))\n",
    "        bottom_right = (center_x + (width // 2) + (expand_by // 2), center_y + (height // 2) + (expand_by // 2))\n",
    "        draw.rectangle([top_left, bottom_right], outline=\"white\", width=2)  # White box on grayscale image\n",
    "\n",
    "    # Display the image\n",
    "    pil_img.show()\n",
    "\n",
    "# Example usage (assuming images and labels are already loaded and preprocessed)\n",
    "if len(images) > 0 and len(labels) > 0:\n",
    "    display_image_with_boxes_pil(images[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation Functions (optional):\n",
    "#Rotate, flip, or crop images to create more diverse training data.\n",
    "# NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution Function:\n",
    "#Applies a convolution operation to an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolve2d(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Apply a 2D convolution operation to an image.\n",
    "    \n",
    "    Args:\n",
    "    image (np.array): The input image array (height, width, channels).\n",
    "    kernel (np.array): The kernel (filter) to apply (height, width).\n",
    "    stride (int): The stride of the convolution.\n",
    "    padding (int): The amount of padding around the image.\n",
    "    \n",
    "    Returns:\n",
    "    np.array: The convolved image.\n",
    "    \"\"\"\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    image_height, image_width, num_channels = image.shape\n",
    "\n",
    "    # Add padding to the image\n",
    "    padded_height = image_height + 2 * padding\n",
    "    padded_width = image_width + 2 * padding\n",
    "    padded_image = np.zeros((padded_height, padded_width, num_channels))\n",
    "    padded_image[padding:padding+image_height, padding:padding+image_width] = image\n",
    "\n",
    "    # Determine the output dimensions\n",
    "    out_height = ((padded_height - kernel_height) // stride) + 1\n",
    "    out_width = ((padded_width - kernel_width) // stride) + 1\n",
    "    output = np.zeros((out_height, out_width, num_channels))\n",
    "\n",
    "    # Perform the convolution operation\n",
    "    for z in range(num_channels):  # Iterate over each channel\n",
    "        for y in range(out_height):\n",
    "            for x in range(out_width):\n",
    "                output[y, x, z] = np.sum(\n",
    "                    kernel * padded_image[\n",
    "                        y * stride : y * stride + kernel_height,\n",
    "                        x * stride : x * stride + kernel_width,\n",
    "                        z\n",
    "                    ]\n",
    "                )\n",
    "    return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from PIL import Image\n",
    "\n",
    "# Load an image and convert to a numpy array\n",
    "img = Image.open('../images/image_1.png')\n",
    "img_np = np.array(img)\n",
    "\n",
    "# Define a simple edge-detection kernel\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "# Apply the convolution operation\n",
    "convolved_image = convolve2d(img_np, kernel, stride=1, padding=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_images(original_img, convolved_img):\n",
    "    \"\"\"\n",
    "    Visualize the original and convolved images side by side.\n",
    "\n",
    "    Args:\n",
    "    original_img (np.array): The original image.\n",
    "    convolved_img (np.array): The image after convolution.\n",
    "    \"\"\"\n",
    "    # Normalize the convolved image for better visualization\n",
    "    convolved_img_normalized = (convolved_img - convolved_img.min()) / (convolved_img.max() - convolved_img.min())\n",
    "\n",
    "    # Plot the original and the convolved images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(original_img, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(convolved_img_normalized, cmap='gray')\n",
    "    axes[1].set_title('Convolved Image')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_your_image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load an image and convert to a numpy array\u001b[39;00m\n\u001b[0;32m      5\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Change this to the path of your image\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convert to grayscale for simplicity\u001b[39;00m\n\u001b[0;32m      7\u001b[0m img_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define a simple edge-detection kernel\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hanso\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_image.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load an image and convert to a numpy array\n",
    "img_path = '../images/image_1.png'  # Change this to the path of your image\n",
    "img = Image.open(img_path).convert('L')  # Convert to grayscale for simplicity\n",
    "img_np = np.array(img)\n",
    "\n",
    "# Define a simple edge-detection kernel\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "# Apply the convolution operation\n",
    "convolved_image = convolve2d(img_np, kernel, stride=1, padding=1)\n",
    "\n",
    "# Visualize the original and the convolved images\n",
    "visualize_images(img_np, convolved_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU Activation Function:\n",
    "#Implements the ReLU activation to introduce non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling Function (optional but recommended):\n",
    "#Applies a max pooling operation to reduce spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten Function:\n",
    "#Converts multi-dimensional arrays into a 1D vector for the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully Connected Layer Function:\n",
    "#Performs linear transformation for classification or coordinate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function:\n",
    "#Computes the error between predicted and actual bounding boxes (e.g., Mean Squared Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer Function:\n",
    "#Adjusts model parameters based on the gradients of the loss function (e.g., SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Loop Function:\n",
    "#Manages the batch processing of images and annotations, forward pass, loss computation, and parameter updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation Function:\n",
    "#Assesses the performance of the model on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bounding Box Prediction Function:\n",
    "#Interprets the network output to predict bounding box coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions:\n",
    "#Includes functions for initializing weights, handling data shuffling, and converting coordinates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
