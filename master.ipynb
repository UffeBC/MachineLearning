{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hej Aleksander ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Aleksander Sønder Kirsblom Salling\n"
     ]
    }
   ],
   "source": [
    "print(\"hi Aleksander Sønder Kirsblom Salling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAGE TO USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this image:\n",
    "from PIL import Image\n",
    "def print_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img.show()\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "image_path = \"./images/image_1.png\"\n",
    "print_image(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DownScale and GrayScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def print_downscaled_images(image_path, downscale_factors):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        original_width, original_height = img.size\n",
    "        \n",
    "        for factor in downscale_factors:\n",
    "            # Convert the image to grayscale\n",
    "            grayscale_img = img.convert(\"L\")\n",
    "            # Resize the grayscale image\n",
    "            downscaled_img = grayscale_img.resize((original_width // factor, original_height // factor))\n",
    "            downscaled_img.show()\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "image_path = \"./images/image_1.png\"\n",
    "downscale_factors = [4] \n",
    "print_downscaled_images(image_path, downscale_factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Input Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes for the input layer: 19200\n"
     ]
    }
   ],
   "source": [
    "preprocessed_img_width = 160\n",
    "preprocessed_img_height = 120\n",
    "\n",
    "# Flattening the preprocessed image data\n",
    "flattened_input_size = preprocessed_img_width * preprocessed_img_height\n",
    "\n",
    "# Number of nodes for the input layer\n",
    "input_nodes = flattened_input_size\n",
    "\n",
    "print(\"Number of nodes for the input layer:\", input_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the input shape based on the number of nodes\n",
    "input_shape = (flattened_input_size,)\n",
    "\n",
    "# Define the forward pass function for the input layer\n",
    "def input_layer_forward(input_data):\n",
    "    return input_data  # No computations performed, input data passed through directly\n",
    "\n",
    "# Example usage: (batch size = 32)\n",
    "input_data = np.random.randn(32, flattened_input_size)  # Example input data\n",
    "output_of_input_layer = input_layer_forward(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the Convolution class\n",
    "class Convolution:\n",
    "    def __init__(self, num_filters, filter_size):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / filter_size\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        h, w = image.shape\n",
    "\n",
    "        for i in range(h - self.filter_size + 1):\n",
    "            for j in range(w - self.filter_size + 1):\n",
    "                region = image[i:(i + self.filter_size), j:(j + self.filter_size)]\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        h, w = input.shape\n",
    "        output = np.zeros((h - self.filter_size + 1, w - self.filter_size + 1, self.num_filters))\n",
    "\n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.sum(region * self.filters, axis=(1, 2))\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pooling class\n",
    "class Pooling:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        h, w, _ = image.shape\n",
    "        new_h = h // self.pool_size\n",
    "        new_w = w // self.pool_size\n",
    "\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                region = image[(i * self.pool_size):(i * self.pool_size + self.pool_size),\n",
    "                               (j * self.pool_size):(j * self.pool_size + self.pool_size)]\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // self.pool_size, w // self.pool_size, num_filters))\n",
    "\n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(region, axis=(0, 1))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Step 1: Load Image\n",
    "def load_image(file_path):\n",
    "    # Use NumPy to load the image from file_path\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess Image\n",
    "def preprocess_image(image):\n",
    "    # Implement preprocessing steps if necessary\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extract Features\n",
    "def extract_features(image):\n",
    "    # Implement feature extraction using NumPy operations\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Classifiers\n",
    "def define_classifiers():\n",
    "    # Define classifiers for small goal, big goal, and table tennis balls\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Predictions\n",
    "def make_predictions(features, classifiers):\n",
    "    # Use classifiers to make predictions on the input features\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Postprocess Predictions\n",
    "def postprocess_predictions(predictions):\n",
    "    # Refine predictions (e.g., thresholding, non-maximum suppression)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualize Results\n",
    "def visualize_results(image, predictions):\n",
    "    # Visualize detected objects on the original image\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    # Step 1: Load Image\n",
    "    image = load_image(\"path/to/image.jpg\")\n",
    "\n",
    "    # Step 2: Preprocess Image\n",
    "    image = preprocess_image(image)\n",
    "\n",
    "    # Step 3: Extract Features\n",
    "    features = extract_features(image)\n",
    "\n",
    "    # Step 4: Define Classifiers\n",
    "    classifiers = define_classifiers()\n",
    "\n",
    "    # Step 5: Predictions\n",
    "    predictions = make_predictions(features, classifiers)\n",
    "\n",
    "    # Step 6: Postprocess Predictions\n",
    "    refined_predictions = postprocess_predictions(predictions)\n",
    "\n",
    "    # Step 7: Visualize Results\n",
    "    visualize_results(image, refined_predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 3: Extract Features\n",
    "def extract_features(image):\n",
    "    # Implement feature extraction using NumPy operations\n",
    "    ...\n",
    "\n",
    "# Step 4: Define Classifiers\n",
    "def define_classifiers():\n",
    "    # Define classifiers for small goal, big goal, and table tennis balls\n",
    "    ...\n",
    "\n",
    "# Step 5: Predictions\n",
    "def make_predictions(features, classifiers):\n",
    "    # Use classifiers to make predictions on the input features\n",
    "    ...\n",
    "\n",
    "# Step 6: Postprocess Predictions\n",
    "def postprocess_predictions(predictions):\n",
    "    # Refine predictions (e.g., thresholding, non-maximum suppression)\n",
    "    ...\n",
    "\n",
    "# Step 7: Visualize Results\n",
    "def visualize_results(image, predictions):\n",
    "    # Visualize detected objects on the original image\n",
    "    ...\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Step 1: Load Image\n",
    "    image = load_image(\"path/to/image.jpg\")\n",
    "\n",
    "    # Step 2: Preprocess Image\n",
    "    image = preprocess_image(image)\n",
    "\n",
    "    # Step 3: Extract Features\n",
    "    features = extract_features(image)\n",
    "\n",
    "    # Step 4: Define Classifiers\n",
    "    classifiers = define_classifiers()\n",
    "\n",
    "    # Step 5: Predictions\n",
    "    predictions = make_predictions(features, classifiers)\n",
    "\n",
    "    # Step 6: Postprocess Predictions\n",
    "    refined_predictions = postprocess_predictions(predictions)\n",
    "\n",
    "    # Step 7: Visualize Results\n",
    "    visualize_results(image, refined_predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
