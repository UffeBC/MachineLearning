{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hej Aleksander ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Aleksander Sønder Kirsblom Salling\n"
     ]
    }
   ],
   "source": [
    "print(\"hi Aleksander Sønder Kirsblom Salling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAGE TO USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this image:\n",
    "from PIL import Image\n",
    "def print_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img.show()\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "image_path = \"./images/image_1.png\"\n",
    "print_image(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DownScale and GrayScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def print_downscaled_images(image_path, downscale_factors):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        original_width, original_height = img.size\n",
    "        \n",
    "        for factor in downscale_factors:\n",
    "            # Convert the image to grayscale\n",
    "            grayscale_img = img.convert(\"L\")\n",
    "            # Resize the grayscale image\n",
    "            downscaled_img = grayscale_img.resize((original_width // factor, original_height // factor))\n",
    "            save_path = \"./images/saved_image.png\"\n",
    "            downscaled_img.save(save_path)\n",
    "            downscaled_img.show()\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "image_path = \"./images/image_1.png\"\n",
    "downscale_factors = [4] \n",
    "print_downscaled_images(image_path, downscale_factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Input Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes for the input layer: 19200\n"
     ]
    }
   ],
   "source": [
    "preprocessed_img_width = 160\n",
    "preprocessed_img_height = 120\n",
    "\n",
    "# Flattening the preprocessed image data\n",
    "flattened_input_size = preprocessed_img_width * preprocessed_img_height\n",
    "\n",
    "# Number of nodes for the input layer\n",
    "input_nodes = flattened_input_size\n",
    "\n",
    "print(\"Number of nodes for the input layer:\", input_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./images/saved_image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define the forward pass function for the input layer\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_layer_forward\u001b[39m(input_data):\n",
      "File \u001b[1;32mc:\\Users\\hanso\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:529\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    527\u001b[0m     deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_animated\u001b[39m\u001b[38;5;124m\"\u001b[39m, plural\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[1;32m--> 529\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the input shape based on the number of nodes\n",
    "input_shape = (flattened_input_size,)\n",
    "input_path = \"./images/saved_image.png\"\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.shape)\n",
    "\n",
    "\n",
    "# Define the forward pass function for the input layer\n",
    "def input_layer_forward(input_data):\n",
    "    return input_data  # No computations performed, input data passed through directly\n",
    "\n",
    "# Example usage: (batch size = 32)\n",
    "#input_data = np.random.randn(32, flattened_input_size)  # Example input data\n",
    "#output_of_input_layer = input_layer_forward(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/image_1.png\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 46\u001b[0m\n\u001b[0;32m     39\u001b[0m gabor_kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[ \u001b[38;5;241m0.01\u001b[39m,  \u001b[38;5;241m0.03\u001b[39m,  \u001b[38;5;241m0.06\u001b[39m,  \u001b[38;5;241m0.03\u001b[39m,  \u001b[38;5;241m0.01\u001b[39m],\n\u001b[0;32m     40\u001b[0m                          [ \u001b[38;5;241m0.07\u001b[39m,  \u001b[38;5;241m0.23\u001b[39m,  \u001b[38;5;241m0.43\u001b[39m,  \u001b[38;5;241m0.23\u001b[39m,  \u001b[38;5;241m0.07\u001b[39m],\n\u001b[0;32m     41\u001b[0m                          [ \u001b[38;5;241m0.12\u001b[39m,  \u001b[38;5;241m0.39\u001b[39m,  \u001b[38;5;241m0.71\u001b[39m,  \u001b[38;5;241m0.39\u001b[39m,  \u001b[38;5;241m0.12\u001b[39m],\n\u001b[0;32m     42\u001b[0m                          [ \u001b[38;5;241m0.07\u001b[39m,  \u001b[38;5;241m0.23\u001b[39m,  \u001b[38;5;241m0.43\u001b[39m,  \u001b[38;5;241m0.23\u001b[39m,  \u001b[38;5;241m0.07\u001b[39m],\n\u001b[0;32m     43\u001b[0m                          [ \u001b[38;5;241m0.01\u001b[39m,  \u001b[38;5;241m0.03\u001b[39m,  \u001b[38;5;241m0.06\u001b[39m,  \u001b[38;5;241m0.03\u001b[39m,  \u001b[38;5;241m0.01\u001b[39m]])\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Perform convolution with Sobel kernels\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m sobel_horizontal_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mconvolve(image_array, sobel_horizontal, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     47\u001b[0m sobel_vertical_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mconvolve(image_array, sobel_vertical, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Perform convolution with Gabor kernel\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconvolve\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hanso\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:851\u001b[0m, in \u001b[0;36mconvolve\u001b[1;34m(a, v, mode)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m multiarray\u001b[38;5;241m.\u001b[39mcorrelate(a, v[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], mode)\n",
      "\u001b[1;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "'''import numpy as np\n",
    "\n",
    "class Convolution:\n",
    "    def __init__(self, num_filters, filter_size):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / filter_size\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        h, w = image.shape\n",
    "\n",
    "        for i in range(h - self.filter_size + 1):\n",
    "            for j in range(w - self.filter_size + 1):\n",
    "                region = image[i:(i + self.filter_size), j:(j + self.filter_size)]\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        h, w = input.shape\n",
    "        output = np.zeros((h - self.filter_size + 1, w - self.filter_size + 1, self.num_filters))\n",
    "\n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.sum(region * self.filters, axis=(1, 2))\n",
    "\n",
    "        return output\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Sobel edge detection kernels\n",
    "sobel_horizontal = np.array([[-1, -2, -1],\n",
    "                             [ 0,  0,  0],\n",
    "                             [ 1,  2,  1]])\n",
    "\n",
    "sobel_vertical = np.array([[-1, 0, 1],\n",
    "                           [-2, 0, 2],\n",
    "                           [-1, 0, 1]])\n",
    "\n",
    "# Gabor texture detection kernel (5x5)\n",
    "gabor_kernel = np.array([[ 0.01,  0.03,  0.06,  0.03,  0.01],\n",
    "                         [ 0.07,  0.23,  0.43,  0.23,  0.07],\n",
    "                         [ 0.12,  0.39,  0.71,  0.39,  0.12],\n",
    "                         [ 0.07,  0.23,  0.43,  0.23,  0.07],\n",
    "                         [ 0.01,  0.03,  0.06,  0.03,  0.01]])\n",
    "\n",
    "# Perform convolution with Sobel kernels\n",
    "sobel_horizontal_output = np.abs(np.convolve(image_array, sobel_horizontal, mode='same'))\n",
    "sobel_vertical_output = np.abs(np.convolve(image_array, sobel_vertical, mode='same'))\n",
    "\n",
    "# Perform convolution with Gabor kernel\n",
    "gabor_output = np.abs(np.convolve(image_array, gabor_kernel, mode='same'))\n",
    "\n",
    "# Display results (you can visualize them using matplotlib or any image processing library)\n",
    "print(\"Sobel Horizontal Output Shape:\", sobel_horizontal_output.shape)\n",
    "print(\"Sobel Vertical Output Shape:\", sobel_vertical_output.shape)\n",
    "print(\"Gabor Output Shape:\", gabor_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pooling class\n",
    "class Pooling:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        h, w, _ = image.shape\n",
    "        new_h = h // self.pool_size\n",
    "        new_w = w // self.pool_size\n",
    "\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                region = image[(i * self.pool_size):(i * self.pool_size + self.pool_size),\n",
    "                               (j * self.pool_size):(j * self.pool_size + self.pool_size)]\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // self.pool_size, w // self.pool_size, num_filters))\n",
    "\n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(region, axis=(0, 1))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Step 1: Load Image\n",
    "def load_image(file_path):\n",
    "    # Use NumPy to load the image from file_path\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess Image\n",
    "def preprocess_image(image):\n",
    "    # Implement preprocessing steps if necessary\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extract Features\n",
    "def extract_features(image):\n",
    "    # Implement feature extraction using NumPy operations\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Classifiers\n",
    "def define_classifiers():\n",
    "    # Define classifiers for small goal, big goal, and table tennis balls\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Predictions\n",
    "def make_predictions(features, classifiers):\n",
    "    # Use classifiers to make predictions on the input features\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Postprocess Predictions\n",
    "def postprocess_predictions(predictions):\n",
    "    # Refine predictions (e.g., thresholding, non-maximum suppression)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualize Results\n",
    "def visualize_results(image, predictions):\n",
    "    # Visualize detected objects on the original image\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    # Step 1: Load Image\n",
    "    image = load_image(\"path/to/image.jpg\")\n",
    "\n",
    "    # Step 2: Preprocess Image\n",
    "    image = preprocess_image(image)\n",
    "\n",
    "    # Step 3: Extract Features\n",
    "    features = extract_features(image)\n",
    "\n",
    "    # Step 4: Define Classifiers\n",
    "    classifiers = define_classifiers()\n",
    "\n",
    "    # Step 5: Predictions\n",
    "    predictions = make_predictions(features, classifiers)\n",
    "\n",
    "    # Step 6: Postprocess Predictions\n",
    "    refined_predictions = postprocess_predictions(predictions)\n",
    "\n",
    "    # Step 7: Visualize Results\n",
    "    visualize_results(image, refined_predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 3: Extract Features\n",
    "def extract_features(image):\n",
    "    # Implement feature extraction using NumPy operations\n",
    "    ...\n",
    "\n",
    "# Step 4: Define Classifiers\n",
    "def define_classifiers():\n",
    "    # Define classifiers for small goal, big goal, and table tennis balls\n",
    "    ...\n",
    "\n",
    "# Step 5: Predictions\n",
    "def make_predictions(features, classifiers):\n",
    "    # Use classifiers to make predictions on the input features\n",
    "    ...\n",
    "\n",
    "# Step 6: Postprocess Predictions\n",
    "def postprocess_predictions(predictions):\n",
    "    # Refine predictions (e.g., thresholding, non-maximum suppression)\n",
    "    ...\n",
    "\n",
    "# Step 7: Visualize Results\n",
    "def visualize_results(image, predictions):\n",
    "    # Visualize detected objects on the original image\n",
    "    ...\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Step 1: Load Image\n",
    "    image = load_image(\"path/to/image.jpg\")\n",
    "\n",
    "    # Step 2: Preprocess Image\n",
    "    image = preprocess_image(image)\n",
    "\n",
    "    # Step 3: Extract Features\n",
    "    features = extract_features(image)\n",
    "\n",
    "    # Step 4: Define Classifiers\n",
    "    classifiers = define_classifiers()\n",
    "\n",
    "    # Step 5: Predictions\n",
    "    predictions = make_predictions(features, classifiers)\n",
    "\n",
    "    # Step 6: Postprocess Predictions\n",
    "    refined_predictions = postprocess_predictions(predictions)\n",
    "\n",
    "    # Step 7: Visualize Results\n",
    "    visualize_results(image, refined_predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
